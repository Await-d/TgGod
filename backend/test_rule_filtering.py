#!/usr/bin/env python3
"""
è§„åˆ™ç­›é€‰é€»è¾‘æµ‹è¯•å·¥å…·
æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡ŒæœåŠ¡ä¸­çš„æ¶ˆæ¯ç­›é€‰è¿‡ç¨‹
"""
import os
import sys
import sqlite3
import json
import logging
from datetime import datetime
from typing import Dict, List, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_multi_rule_filtering(task_id: int):
    """æµ‹è¯•å¤šè§„åˆ™ç­›é€‰é€»è¾‘ï¼Œæ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡ŒæœåŠ¡çš„ç­›é€‰è¿‡ç¨‹"""
    db_path = "/app/data/tggod.db"
    
    if not os.path.exists(db_path):
        logger.error(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        cursor.execute("SELECT * FROM download_tasks WHERE id = ?", (task_id,))
        task_row = cursor.fetchone()
        if not task_row:
            logger.error(f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨")
            return False
        
        cursor.execute("PRAGMA table_info(download_tasks)")
        task_columns = [col[1] for col in cursor.fetchall()]
        task_dict = dict(zip(task_columns, task_row))
        
        logger.info(f"ğŸ§ª æµ‹è¯•ä»»åŠ¡ {task_id} çš„è§„åˆ™ç­›é€‰é€»è¾‘")
        logger.info("=" * 60)
        logger.info(f"ä»»åŠ¡åç§°: {task_dict['name']}")
        logger.info(f"ç›®æ ‡ç¾¤ç»„ ID: {task_dict['group_id']}")
        
        # è·å–ä»»åŠ¡å…³è”çš„æ‰€æœ‰è§„åˆ™
        cursor.execute("""
            SELECT tra.rule_id, tra.is_active, tra.priority, fr.name
            FROM task_rule_associations tra
            JOIN filter_rules fr ON tra.rule_id = fr.id
            WHERE tra.task_id = ?
            ORDER BY tra.priority DESC
        """, (task_id,))
        rule_associations = cursor.fetchall()
        
        if not rule_associations:
            logger.error("ä»»åŠ¡æ²¡æœ‰å…³è”çš„è§„åˆ™")
            return False
            
        logger.info(f"å…³è”è§„åˆ™æ•°é‡: {len(rule_associations)}")
        
        # è·å–ç¾¤ç»„åŸºç¡€æ¶ˆæ¯ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM telegram_messages WHERE group_id = ?", (task_dict['group_id'],))
        total_messages = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT COUNT(*) FROM telegram_messages 
            WHERE group_id = ? AND media_type IS NOT NULL AND media_type != 'text'
        """, (task_dict['group_id'],))
        media_messages = cursor.fetchone()[0]
        
        logger.info(f"ç¾¤ç»„æ€»æ¶ˆæ¯æ•°: {total_messages}")
        logger.info(f"ç¾¤ç»„æœ‰åª’ä½“æ¶ˆæ¯æ•°: {media_messages}")
        
        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡ŒæœåŠ¡çš„å¤šè§„åˆ™ORç­›é€‰é€»è¾‘
        logger.info(f"\nğŸ” æ¨¡æ‹Ÿå¤šè§„åˆ™ORç­›é€‰é€»è¾‘:")
        
        # æ”¶é›†æ‰€æœ‰æ´»è·ƒè§„åˆ™çš„è¯¦ç»†é…ç½®
        active_rules_data = []
        for rule_id, is_active, priority, rule_name in rule_associations:
            if not is_active:
                logger.info(f"è·³è¿‡éæ´»è·ƒè§„åˆ™: {rule_name}")
                continue
                
            cursor.execute("SELECT * FROM filter_rules WHERE id = ?", (rule_id,))
            rule_row = cursor.fetchone()
            if rule_row:
                cursor.execute("PRAGMA table_info(filter_rules)")
                rule_columns = [col[1] for col in cursor.fetchall()]
                rule_dict = dict(zip(rule_columns, rule_row))
                active_rules_data.append({
                    'id': rule_id,
                    'name': rule_name,
                    'priority': priority,
                    'config': rule_dict
                })
        
        logger.info(f"æ´»è·ƒè§„åˆ™æ•°é‡: {len(active_rules_data)}")
        
        # ä¸ºæ¯ä¸ªè§„åˆ™åˆ›å»ºå­æŸ¥è¯¢
        rule_conditions = []
        rule_results = []
        
        for rule_data in active_rules_data:
            rule_config = rule_data['config']
            logger.info(f"\nğŸ“‹ å¤„ç†è§„åˆ™: {rule_data['name']} (ID: {rule_data['id']})")
            
            # æ„å»ºåŸºç¡€æŸ¥è¯¢
            query = """
                SELECT id, message_id, text, media_type, media_size, media_filename, 
                       sender_username, view_count, is_forwarded, date
                FROM telegram_messages 
                WHERE group_id = ? AND media_type IS NOT NULL AND media_type != 'text'
            """
            params = [task_dict['group_id']]
            
            # åº”ç”¨å…³é”®è¯ç­›é€‰
            if rule_config.get('keywords'):
                try:
                    keywords = json.loads(rule_config['keywords']) if isinstance(rule_config['keywords'], str) else rule_config['keywords']
                    if keywords:
                        keyword_conditions = []
                        for keyword in keywords:
                            keyword_conditions.append("text LIKE ?")
                            params.append(f"%{keyword}%")
                        query += f" AND ({' OR '.join(keyword_conditions)})"
                        logger.info(f"   åº”ç”¨å…³é”®è¯ç­›é€‰: {keywords}")
                except:
                    pass
            
            # åº”ç”¨æ’é™¤å…³é”®è¯ç­›é€‰
            if rule_config.get('exclude_keywords'):
                try:
                    exclude_keywords = json.loads(rule_config['exclude_keywords']) if isinstance(rule_config['exclude_keywords'], str) else rule_config['exclude_keywords']
                    if exclude_keywords:
                        for exclude_keyword in exclude_keywords:
                            query += " AND (text NOT LIKE ? OR text IS NULL)"
                            params.append(f"%{exclude_keyword}%")
                        logger.info(f"   åº”ç”¨æ’é™¤å…³é”®è¯ç­›é€‰: {exclude_keywords}")
                except:
                    pass
            
            # åº”ç”¨åª’ä½“ç±»å‹ç­›é€‰
            if rule_config.get('media_types'):
                try:
                    media_types = json.loads(rule_config['media_types']) if isinstance(rule_config['media_types'], str) else rule_config['media_types']
                    if media_types:
                        type_conditions = []
                        for media_type in media_types:
                            type_conditions.append("media_type = ?")
                            params.append(media_type)
                        query += f" AND ({' OR '.join(type_conditions)})"
                        logger.info(f"   åº”ç”¨åª’ä½“ç±»å‹ç­›é€‰: {media_types}")
                except:
                    pass
            
            # åº”ç”¨æ–‡ä»¶å¤§å°ç­›é€‰
            if rule_config.get('min_file_size'):
                query += " AND media_size >= ?"
                params.append(rule_config['min_file_size'])
                logger.info(f"   åº”ç”¨æœ€å°æ–‡ä»¶å¤§å°ç­›é€‰: {rule_config['min_file_size']} å­—èŠ‚")
            
            if rule_config.get('max_file_size'):
                query += " AND media_size <= ?"
                params.append(rule_config['max_file_size'])
                logger.info(f"   åº”ç”¨æœ€å¤§æ–‡ä»¶å¤§å°ç­›é€‰: {rule_config['max_file_size']} å­—èŠ‚")
            
            # åº”ç”¨æµè§ˆé‡ç­›é€‰
            if rule_config.get('min_views'):
                query += " AND (view_count >= ? OR view_count IS NULL)"
                params.append(rule_config['min_views'])
                logger.info(f"   åº”ç”¨æœ€å°æµè§ˆé‡ç­›é€‰: {rule_config['min_views']}")
            
            if rule_config.get('max_views'):
                query += " AND view_count <= ?"
                params.append(rule_config['max_views'])
                logger.info(f"   åº”ç”¨æœ€å¤§æµè§ˆé‡ç­›é€‰: {rule_config['max_views']}")
            
            # åº”ç”¨è½¬å‘ç­›é€‰
            if not rule_config.get('include_forwarded', True):
                query += " AND is_forwarded = 0"
                logger.info("   åº”ç”¨è½¬å‘ç­›é€‰: æ’é™¤è½¬å‘æ¶ˆæ¯")
            
            # æ‰§è¡Œå•ä¸ªè§„åˆ™æŸ¥è¯¢
            cursor.execute(query, params)
            rule_results_data = cursor.fetchall()
            rule_results.append({
                'rule_name': rule_data['name'],
                'rule_id': rule_data['id'],
                'count': len(rule_results_data),
                'messages': rule_results_data[:5]  # åªä¿ç•™å‰5æ¡æ¶ˆæ¯ç”¨äºå±•ç¤º
            })
            
            logger.info(f"   âœ… è§„åˆ™ç­›é€‰ç»“æœ: {len(rule_results_data)} æ¡æ¶ˆæ¯")
        
        # åˆå¹¶æ‰€æœ‰è§„åˆ™çš„ç»“æœï¼ˆæ¨¡æ‹ŸORé€»è¾‘ï¼‰
        logger.info(f"\nğŸ”— åˆå¹¶æ‰€æœ‰è§„åˆ™ç»“æœ (ORé€»è¾‘):")
        all_message_ids = set()
        for result in rule_results:
            for message in result['messages']:
                all_message_ids.add(message[0])  # message[0] is id
        
        # è·å–æœ€ç»ˆç­›é€‰ç»“æœ
        if all_message_ids:
            cursor.execute(f"""
                SELECT COUNT(*) FROM telegram_messages 
                WHERE id IN ({','.join('?' * len(all_message_ids))})
            """, list(all_message_ids))
            final_count = cursor.fetchone()[0]
        else:
            final_count = 0
        
        logger.info(f"æœ€ç»ˆç­›é€‰ç»“æœ: {final_count} æ¡æ¶ˆæ¯ (å»é‡å)")
        
        # æ˜¾ç¤ºæ¯ä¸ªè§„åˆ™çš„è¯¦ç»†ç»“æœ
        logger.info(f"\nğŸ“Š å„è§„åˆ™ç­›é€‰è¯¦æƒ…:")
        for result in rule_results:
            logger.info(f"è§„åˆ™ '{result['rule_name']}': {result['count']} æ¡æ¶ˆæ¯")
            if result['messages']:
                logger.info("   ç¤ºä¾‹æ¶ˆæ¯:")
                for msg in result['messages'][:3]:
                    msg_text = (msg[2] or '')[:100] + '...' if msg[2] and len(msg[2]) > 100 else msg[2] or 'æ— æ–‡æœ¬'
                    logger.info(f"     - ID {msg[1]}: {msg_text} ({msg[3]}, {msg[4]} bytes)")
        
        # ä¸ä»»åŠ¡æ‰§è¡Œç»“æœå¯¹æ¯”
        logger.info(f"\nğŸ“ˆ ä¸ä»»åŠ¡æ‰§è¡Œç»“æœå¯¹æ¯”:")
        logger.info(f"ä»»åŠ¡è®°å½•çš„æ€»æ¶ˆæ¯æ•°: {task_dict.get('total_messages', 0)}")
        logger.info(f"ä»»åŠ¡è®°å½•çš„å·²ä¸‹è½½æ•°: {task_dict.get('downloaded_messages', 0)}")
        logger.info(f"ç­›é€‰æµ‹è¯•ç»“æœ: {final_count}")
        
        if final_count != task_dict.get('total_messages', 0):
            logger.warning("âš ï¸ ç­›é€‰ç»“æœä¸ä»»åŠ¡è®°å½•ä¸åŒ¹é…ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜!")
        else:
            logger.info("âœ… ç­›é€‰ç»“æœä¸ä»»åŠ¡è®°å½•åŒ¹é…")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è§„åˆ™ç­›é€‰é€»è¾‘æµ‹è¯•å·¥å…·")
    parser.add_argument("task_id", type=int, help="è¦æµ‹è¯•çš„ä»»åŠ¡ID")
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¯åŠ¨è§„åˆ™ç­›é€‰é€»è¾‘æµ‹è¯•")
    
    success = test_multi_rule_filtering(args.task_id)
    
    if success:
        logger.info("âœ… æµ‹è¯•å®Œæˆ")
        sys.exit(0)
    else:
        logger.error("âŒ æµ‹è¯•å¤±è´¥")
        sys.exit(1)