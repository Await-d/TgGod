#!/usr/bin/env python3
"""
æ•°æ®åº“é”å®šä¿®å¤éªŒè¯è„šæœ¬
æµ‹è¯•ä¿®å¤åçš„ä»»åŠ¡æ‰§è¡Œç¨³å®šæ€§
"""

import asyncio
import logging
import os
import sys
import time
import random
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.services.task_db_manager import task_db_manager
from app.models.rule import DownloadTask
from app.models.log import TaskLog
from app.database import SessionLocal

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseStressTest:
    """æ•°æ®åº“å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {
            "concurrent_sessions": 0,
            "successful_operations": 0,
            "failed_operations": 0,
            "lock_errors": 0,
            "total_time": 0,
            "operations_per_second": 0
        }
    
    async def test_concurrent_progress_updates(self, num_tasks: int = 5, updates_per_task: int = 20):
        """æµ‹è¯•å¹¶å‘è¿›åº¦æ›´æ–°"""
        logger.info(f"å¼€å§‹å¹¶å‘è¿›åº¦æ›´æ–°æµ‹è¯•: {num_tasks} ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ {updates_per_task} æ¬¡æ›´æ–°")
        
        async def update_task_progress(task_id: int, updates: int):
            """æ¨¡æ‹Ÿä»»åŠ¡è¿›åº¦æ›´æ–°"""
            for i in range(updates):
                try:
                    progress = min(int((i + 1) / updates * 100), 100)
                    downloaded_count = i + 1
                    
                    async with task_db_manager.get_task_session(task_id, "progress") as session:
                        # æ¨¡æ‹ŸæŸ¥æ‰¾ä»»åŠ¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        task = session.query(DownloadTask).filter(DownloadTask.id == task_id).first()
                        if not task:
                            # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
                            task = DownloadTask(
                                name=f"æµ‹è¯•ä»»åŠ¡_{task_id}",
                                group_id=1,
                                rule_id=1,
                                status="running",
                                progress=0,
                                download_path="/tmp/test"
                            )
                            session.add(task)
                            session.flush()
                        
                        # æ›´æ–°è¿›åº¦
                        task.progress = progress
                        task.downloaded_messages = downloaded_count
                        session.commit()
                    
                    self.test_results["successful_operations"] += 1
                    
                    # æ¨¡æ‹ŸçœŸå®ä»»åŠ¡é—´çš„çŸ­å»¶è¿Ÿ
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    self.test_results["failed_operations"] += 1
                    if "locked" in str(e).lower() or "busy" in str(e).lower():
                        self.test_results["lock_errors"] += 1
                    logger.error(f"ä»»åŠ¡ {task_id} è¿›åº¦æ›´æ–°å¤±è´¥: {e}")
        
        # å¯åŠ¨å¹¶å‘ä»»åŠ¡
        start_time = time.time()
        tasks = []
        for task_id in range(1, num_tasks + 1):
            task = asyncio.create_task(update_task_progress(task_id, updates_per_task))
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        self.test_results["total_time"] = end_time - start_time
        total_operations = self.test_results["successful_operations"] + self.test_results["failed_operations"]
        if self.test_results["total_time"] > 0:
            self.test_results["operations_per_second"] = total_operations / self.test_results["total_time"]
        
        logger.info(f"å¹¶å‘è¿›åº¦æ›´æ–°æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {self.test_results['total_time']:.2f} ç§’")
    
    async def test_concurrent_log_writes(self, num_loggers: int = 10, logs_per_logger: int = 50):
        """æµ‹è¯•å¹¶å‘æ—¥å¿—å†™å…¥"""
        logger.info(f"å¼€å§‹å¹¶å‘æ—¥å¿—å†™å…¥æµ‹è¯•: {num_loggers} ä¸ªæ—¥å¿—å™¨ï¼Œæ¯ä¸ªå†™å…¥ {logs_per_logger} æ¡æ—¥å¿—")
        
        async def write_task_logs(task_id: int, log_count: int):
            """æ¨¡æ‹Ÿä»»åŠ¡æ—¥å¿—å†™å…¥"""
            for i in range(log_count):
                try:
                    async with task_db_manager.get_task_session(task_id, "log") as session:
                        log_entry = TaskLog(
                            task_id=task_id,
                            level=random.choice(["INFO", "WARNING", "ERROR"]),
                            message=f"æµ‹è¯•æ—¥å¿—æ¶ˆæ¯ {i+1} from task {task_id}",
                            details={"test": True, "iteration": i+1}
                        )
                        session.add(log_entry)
                        session.commit()
                    
                    self.test_results["successful_operations"] += 1
                    
                    # æ¨¡æ‹ŸçœŸå®æ—¥å¿—é—´çš„å»¶è¿Ÿ
                    await asyncio.sleep(0.05)
                    
                except Exception as e:
                    self.test_results["failed_operations"] += 1
                    if "locked" in str(e).lower():
                        self.test_results["lock_errors"] += 1
                    logger.error(f"ä»»åŠ¡ {task_id} æ—¥å¿—å†™å…¥å¤±è´¥: {e}")
        
        # å¯åŠ¨å¹¶å‘æ—¥å¿—å†™å…¥
        start_time = time.time()
        tasks = []
        for task_id in range(1, num_loggers + 1):
            task = asyncio.create_task(write_task_logs(task_id, logs_per_logger))
            tasks.append(task)
        
        await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        log_test_time = end_time - start_time
        logger.info(f"å¹¶å‘æ—¥å¿—å†™å…¥æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {log_test_time:.2f} ç§’")
    
    async def test_mixed_operations(self, duration_seconds: int = 30):
        """æµ‹è¯•æ··åˆæ“ä½œ"""
        logger.info(f"å¼€å§‹æ··åˆæ“ä½œæµ‹è¯•ï¼ŒæŒç»­ {duration_seconds} ç§’")
        
        async def random_database_operation():
            """éšæœºæ•°æ®åº“æ“ä½œ"""
            operation_type = random.choice(["progress", "log", "completion"])
            task_id = random.randint(1, 5)
            
            try:
                if operation_type == "progress":
                    async with task_db_manager.get_task_session(task_id, "progress") as session:
                        task = session.query(DownloadTask).filter(DownloadTask.id == task_id).first()
                        if task:
                            task.progress = random.randint(0, 100)
                            task.downloaded_messages = random.randint(0, 1000)
                            session.commit()
                
                elif operation_type == "log":
                    async with task_db_manager.get_task_session(task_id, "log") as session:
                        log_entry = TaskLog(
                            task_id=task_id,
                            level=random.choice(["INFO", "WARNING", "ERROR"]),
                            message=f"éšæœºæµ‹è¯•æ—¥å¿— {time.time()}",
                            details={"random_test": True}
                        )
                        session.add(log_entry)
                        session.commit()
                
                elif operation_type == "completion":
                    await task_db_manager.quick_status_update(
                        task_id, 
                        random.choice(["completed", "failed"]),
                        "æµ‹è¯•çŠ¶æ€æ›´æ–°"
                    )
                
                self.test_results["successful_operations"] += 1
                
            except Exception as e:
                self.test_results["failed_operations"] += 1
                if "locked" in str(e).lower():
                    self.test_results["lock_errors"] += 1
        
        # æŒç»­è¿è¡Œæ··åˆæ“ä½œ
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        tasks = []
        while time.time() < end_time:
            # æ¯æ¬¡å¯åŠ¨1-3ä¸ªå¹¶å‘æ“ä½œ
            num_concurrent = random.randint(1, 3)
            batch_tasks = []
            for _ in range(num_concurrent):
                task = asyncio.create_task(random_database_operation())
                batch_tasks.append(task)
            
            # ç­‰å¾…è¿™æ‰¹æ“ä½œå®Œæˆ
            await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # çŸ­æš‚å»¶è¿Ÿ
            await asyncio.sleep(random.uniform(0.1, 0.5))
        
        actual_time = time.time() - start_time
        logger.info(f"æ··åˆæ“ä½œæµ‹è¯•å®Œæˆï¼Œå®é™…è€—æ—¶: {actual_time:.2f} ç§’")
    
    def print_test_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        logger.info("=" * 60)
        logger.info("æ•°æ®åº“é”å®šä¿®å¤éªŒè¯ç»“æœ")
        logger.info("=" * 60)
        
        total_operations = self.test_results["successful_operations"] + self.test_results["failed_operations"]
        success_rate = (self.test_results["successful_operations"] / max(total_operations, 1)) * 100
        
        logger.info(f"æ€»æ“ä½œæ•°: {total_operations}")
        logger.info(f"æˆåŠŸæ“ä½œ: {self.test_results['successful_operations']}")
        logger.info(f"å¤±è´¥æ“ä½œ: {self.test_results['failed_operations']}")
        logger.info(f"é”å®šé”™è¯¯: {self.test_results['lock_errors']}")
        logger.info(f"æˆåŠŸç‡: {success_rate:.2f}%")
        logger.info(f"æ€»è€—æ—¶: {self.test_results['total_time']:.2f} ç§’")
        logger.info(f"æ“ä½œ/ç§’: {self.test_results['operations_per_second']:.2f}")
        
        # è¯„ä¼°ç»“æœ
        if success_rate >= 95 and self.test_results['lock_errors'] <= total_operations * 0.02:
            logger.info("âœ… æµ‹è¯•é€šè¿‡ï¼šæ•°æ®åº“é”å®šé—®é¢˜å·²å¾—åˆ°æ˜¾è‘—æ”¹å–„")
            return True
        elif success_rate >= 85:
            logger.warning("âš ï¸ æµ‹è¯•éƒ¨åˆ†é€šè¿‡ï¼šä»æœ‰ä¸€äº›é”å®šé—®é¢˜ï¼Œä½†å·²æœ‰æ”¹å–„")
            return True
        else:
            logger.error("âŒ æµ‹è¯•å¤±è´¥ï¼šæ•°æ®åº“é”å®šé—®é¢˜ä»ç„¶ä¸¥é‡")
            return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æ•°æ®åº“é”å®šä¿®å¤éªŒè¯æµ‹è¯•")
    
    stress_test = DatabaseStressTest()
    
    try:
        # æµ‹è¯•1: å¹¶å‘è¿›åº¦æ›´æ–°
        await stress_test.test_concurrent_progress_updates(num_tasks=8, updates_per_task=25)
        
        # çŸ­æš‚ä¼‘æ¯
        await asyncio.sleep(2)
        
        # æµ‹è¯•2: å¹¶å‘æ—¥å¿—å†™å…¥
        await stress_test.test_concurrent_log_writes(num_loggers=12, logs_per_logger=30)
        
        # çŸ­æš‚ä¼‘æ¯
        await asyncio.sleep(2)
        
        # æµ‹è¯•3: æ··åˆæ“ä½œå‹åŠ›æµ‹è¯•
        await stress_test.test_mixed_operations(duration_seconds=45)
        
        # æ¸…ç†ä¼šè¯
        await task_db_manager.cleanup_sessions()
        
        # æ‰“å°ç»“æœ
        test_passed = stress_test.print_test_results()
        
        if test_passed:
            logger.info("ğŸ‰ æ•°æ®åº“é”å®šä¿®å¤éªŒè¯æˆåŠŸï¼")
            return True
        else:
            logger.error("ğŸ’¥ æ•°æ®åº“é”å®šä¿®å¤éªŒè¯å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            return False
            
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)