"""
SQLiteè¿ç§»ç®¡ç†å™¨
ä¸“é—¨å¤„ç†SQLiteä¸æ”¯æŒçš„DDLæ“ä½œï¼Œå¦‚DROP COLUMN
ä½¿ç”¨è¡¨é‡å»ºç­–ç•¥å®ç°å®Œæ•´çš„è¿ç§»åŠŸèƒ½
"""
import os
import sqlite3
import logging
import asyncio
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import shutil
import tempfile
import json
from datetime import datetime
from contextlib import contextmanager
from sqlalchemy import create_engine, text, inspect
from sqlalchemy.engine import Engine

logger = logging.getLogger(__name__)

class SQLiteMigrationManager:
    """SQLiteæ•°æ®åº“è¿ç§»ç®¡ç†å™¨"""
    
    def __init__(self, database_url: str, backup_dir: str = None):
        self.database_url = database_url
        self.database_path = database_url.replace('sqlite:///', '')
        self.backup_dir = Path(backup_dir) if backup_dir else Path(self.database_path).parent / 'backups'
        self.backup_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºSQLAlchemyå¼•æ“
        self.engine = create_engine(database_url, echo=False)
        
        # è¿ç§»çŠ¶æ€è·Ÿè¸ª
        self.migration_log = []
        self.current_backup = None
    
    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        connection = self.engine.connect()
        try:
            yield connection
        finally:
            connection.close()
    
    def create_backup(self, suffix: str = None) -> str:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        suffix_str = f"_{suffix}" if suffix else ""
        backup_filename = f"tggod_backup_{timestamp}{suffix_str}.db"
        backup_path = self.backup_dir / backup_filename
        
        try:
            # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            shutil.copy2(self.database_path, backup_path)
            self.current_backup = str(backup_path)
            
            logger.info(f"ğŸ“¦ æ•°æ®åº“å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_path}")
            
            # éªŒè¯å¤‡ä»½å®Œæ•´æ€§
            if self._verify_backup_integrity(backup_path):
                return str(backup_path)
            else:
                raise Exception("å¤‡ä»½å®Œæ•´æ€§éªŒè¯å¤±è´¥")
                
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            raise
    
    def _verify_backup_integrity(self, backup_path: Path) -> bool:
        """éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            with sqlite3.connect(str(backup_path)) as conn:
                # æ‰§è¡ŒPRAGMAå®Œæ•´æ€§æ£€æŸ¥
                result = conn.execute("PRAGMA integrity_check").fetchone()
                is_valid = result and result[0] == "ok"
                
                if is_valid:
                    logger.info("âœ… å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                else:
                    logger.error(f"âŒ å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥: {result}")
                
                return is_valid
                
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½å®Œæ•´æ€§éªŒè¯å¼‚å¸¸: {e}")
            return False
    
    def restore_from_backup(self, backup_path: str = None) -> bool:
        """ä»å¤‡ä»½æ¢å¤æ•°æ®åº“"""
        try:
            backup_to_restore = backup_path or self.current_backup
            
            if not backup_to_restore or not os.path.exists(backup_to_restore):
                raise Exception("å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæŒ‡å®š")
            
            logger.info(f"ğŸ”„ å¼€å§‹ä»å¤‡ä»½æ¢å¤æ•°æ®åº“: {backup_to_restore}")
            
            # å…³é—­å½“å‰è¿æ¥
            self.engine.dispose()
            
            # æ¢å¤æ•°æ®åº“æ–‡ä»¶
            shutil.copy2(backup_to_restore, self.database_path)
            
            # é‡æ–°åˆ›å»ºå¼•æ“
            self.engine = create_engine(self.database_url, echo=False)
            
            logger.info("âœ… æ•°æ®åº“æ¢å¤æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {e}")
            return False
    
    def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        try:
            with self.get_connection() as conn:
                # è·å–è¡¨çš„åˆ›å»ºSQL
                create_sql_result = conn.execute(text(
                    "SELECT sql FROM sqlite_master WHERE type='table' AND name=:table_name"
                ), {"table_name": table_name}).fetchone()
                
                if not create_sql_result:
                    raise Exception(f"è¡¨ {table_name} ä¸å­˜åœ¨")
                
                # è·å–åˆ—ä¿¡æ¯
                columns_result = conn.execute(text(f"PRAGMA table_info({table_name})")).fetchall()
                
                # è·å–ç´¢å¼•ä¿¡æ¯
                indexes_result = conn.execute(text(
                    "SELECT name, sql FROM sqlite_master WHERE type='index' AND tbl_name=:table_name"
                ), {"table_name": table_name}).fetchall()
                
                # è·å–è§¦å‘å™¨ä¿¡æ¯
                triggers_result = conn.execute(text(
                    "SELECT name, sql FROM sqlite_master WHERE type='trigger' AND tbl_name=:table_name"
                ), {"table_name": table_name}).fetchall()
                
                return {
                    "create_sql": create_sql_result[0],
                    "columns": [
                        {
                            "cid": row[0],
                            "name": row[1],
                            "type": row[2],
                            "notnull": bool(row[3]),
                            "default_value": row[4],
                            "pk": bool(row[5])
                        }
                        for row in columns_result
                    ],
                    "indexes": [
                        {"name": row[0], "sql": row[1]}
                        for row in indexes_result
                        if row[1]  # æ’é™¤è‡ªåŠ¨ç´¢å¼•
                    ],
                    "triggers": [
                        {"name": row[0], "sql": row[1]}
                        for row in triggers_result
                    ]
                }
                
        except Exception as e:
            logger.error(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
            raise
    
    def rebuild_table_drop_columns(self, table_name: str, columns_to_drop: List[str],
                                   progress_callback=None) -> bool:
        """é€šè¿‡é‡å»ºè¡¨çš„æ–¹å¼åˆ é™¤åˆ—"""
        try:
            logger.info(f"ğŸ”§ å¼€å§‹é‡å»ºè¡¨ {table_name}ï¼Œåˆ é™¤åˆ—: {', '.join(columns_to_drop)}")
            
            # æ­¥éª¤1: åˆ›å»ºå¤‡ä»½
            backup_path = self.create_backup(f"drop_columns_{table_name}")
            
            # æ­¥éª¤2: è·å–åŸè¡¨ç»“æ„
            schema = self.get_table_schema(table_name)
            original_columns = schema["columns"]
            
            # æ­¥éª¤3: è®¡ç®—æ–°è¡¨çš„åˆ—
            new_columns = [col for col in original_columns if col["name"] not in columns_to_drop]
            
            if len(new_columns) == len(original_columns):
                logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆ é™¤çš„åˆ—")
                return True
            
            # æ­¥éª¤4: ç”Ÿæˆæ–°è¡¨çš„CREATEè¯­å¥
            new_create_sql = self._generate_new_create_sql(
                table_name, new_columns, schema["create_sql"]
            )
            
            # æ­¥éª¤5: æ‰§è¡Œè¡¨é‡å»º
            with self.get_connection() as conn:
                # å¼€å§‹äº‹åŠ¡
                trans = conn.begin()
                
                try:
                    # æŠ¥å‘Šè¿›åº¦
                    if progress_callback:
                        try:
                            progress_callback("åˆ›å»ºä¸´æ—¶è¡¨")
                        except Exception as e:
                            logger.warning(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
                    
                    # åˆ›å»ºä¸´æ—¶è¡¨
                    temp_table_name = f"{table_name}_temp_{int(datetime.now().timestamp())}"
                    temp_create_sql = new_create_sql.replace(table_name, temp_table_name)
                    conn.execute(text(temp_create_sql))
                    
                    # æŠ¥å‘Šè¿›åº¦
                    if progress_callback:
                        try:
                            progress_callback("å¤åˆ¶æ•°æ®")
                        except Exception as e:
                            logger.warning(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
                    
                    # å¤åˆ¶æ•°æ®
                    column_names = [col["name"] for col in new_columns]
                    columns_str = ", ".join(column_names)
                    
                    copy_sql = f"""
                        INSERT INTO {temp_table_name} ({columns_str})
                        SELECT {columns_str} FROM {table_name}
                    """
                    
                    conn.execute(text(copy_sql))
                    
                    # æŠ¥å‘Šè¿›åº¦
                    if progress_callback:
                        try:
                            progress_callback("é‡å»ºç´¢å¼•")
                        except Exception as e:
                            logger.warning(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
                    
                    # åˆ é™¤åŸè¡¨
                    conn.execute(text(f"DROP TABLE {table_name}"))
                    
                    # é‡å‘½åä¸´æ—¶è¡¨
                    conn.execute(text(f"ALTER TABLE {temp_table_name} RENAME TO {table_name}"))
                    
                    # é‡å»ºç´¢å¼•
                    for index in schema["indexes"]:
                        if index["sql"]:
                            conn.execute(text(index["sql"]))
                    
                    # é‡å»ºè§¦å‘å™¨
                    for trigger in schema["triggers"]:
                        if trigger["sql"]:
                            conn.execute(text(trigger["sql"]))
                    
                    # æäº¤äº‹åŠ¡
                    trans.commit()
                    
                    logger.info(f"âœ… è¡¨ {table_name} é‡å»ºæˆåŠŸï¼Œåˆ é™¤äº† {len(columns_to_drop)} ä¸ªåˆ—")
                    
                    # è®°å½•è¿ç§»æ—¥å¿—
                    self.migration_log.append({
                        "timestamp": datetime.now().isoformat(),
                        "operation": "drop_columns",
                        "table": table_name,
                        "dropped_columns": columns_to_drop,
                        "backup": backup_path,
                        "success": True
                    })
                    
                    return True
                    
                except Exception as e:
                    # å›æ»šäº‹åŠ¡
                    trans.rollback()
                    logger.error(f"âŒ è¡¨é‡å»ºå¤±è´¥ï¼Œæ­£åœ¨å›æ»š: {e}")
                    
                    # ä»å¤‡ä»½æ¢å¤
                    self.restore_from_backup(backup_path)
                    
                    # è®°å½•å¤±è´¥æ—¥å¿—
                    self.migration_log.append({
                        "timestamp": datetime.now().isoformat(),
                        "operation": "drop_columns",
                        "table": table_name,
                        "dropped_columns": columns_to_drop,
                        "backup": backup_path,
                        "success": False,
                        "error": str(e)
                    })
                    
                    raise
                    
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤åˆ—æ“ä½œå¤±è´¥: {e}")
            return False
    
    def _generate_new_create_sql(self, table_name: str, columns: List[Dict], 
                               original_sql: str) -> str:
        """ç”Ÿæˆæ–°è¡¨çš„CREATE SQLè¯­å¥"""
        # æ„å»ºåˆ—å®šä¹‰
        column_defs = []
        primary_keys = []
        
        for col in columns:
            col_def = f"{col['name']} {col['type']}"
            
            if col["notnull"]:
                col_def += " NOT NULL"
            
            if col["default_value"] is not None:
                col_def += f" DEFAULT {col['default_value']}"
            
            if col["pk"]:
                primary_keys.append(col["name"])
            
            column_defs.append(col_def)
        
        # æ·»åŠ ä¸»é”®çº¦æŸ
        if primary_keys:
            if len(primary_keys) == 1 and not any("AUTOINCREMENT" in original_sql.upper() for _ in [1]):
                # å•ä¸»é”®ï¼Œå¯èƒ½éœ€è¦AUTOINCREMENT
                if "AUTOINCREMENT" in original_sql.upper():
                    column_defs[0] += " PRIMARY KEY AUTOINCREMENT"
                else:
                    column_defs[0] += " PRIMARY KEY"
            else:
                # å¤åˆä¸»é”®
                column_defs.append(f"PRIMARY KEY ({', '.join(primary_keys)})")
        
        # æ„å»ºå®Œæ•´çš„CREATEè¯­å¥
        columns_str = ",\n    ".join(column_defs)
        create_sql = f"CREATE TABLE {table_name} (\n    {columns_str}\n)"
        
        return create_sql
    
    def add_columns(self, table_name: str, columns: List[Dict[str, Any]]) -> bool:
        """æ·»åŠ åˆ—ï¼ˆSQLiteåŸç”Ÿæ”¯æŒï¼‰"""
        try:
            logger.info(f"ğŸ”§ ä¸ºè¡¨ {table_name} æ·»åŠ åˆ—: {[col['name'] for col in columns]}")
            
            # åˆ›å»ºå¤‡ä»½
            backup_path = self.create_backup(f"add_columns_{table_name}")
            
            with self.get_connection() as conn:
                for col in columns:
                    col_def = f"{col['name']} {col['type']}"
                    
                    if col.get('not_null', False):
                        col_def += " NOT NULL"
                    
                    if col.get('default') is not None:
                        col_def += f" DEFAULT {col['default']}"
                    
                    add_sql = f"ALTER TABLE {table_name} ADD COLUMN {col_def}"
                    conn.execute(text(add_sql))
                
                conn.commit()
            
            logger.info(f"âœ… æˆåŠŸä¸ºè¡¨ {table_name} æ·»åŠ äº† {len(columns)} ä¸ªåˆ—")
            
            # è®°å½•è¿ç§»æ—¥å¿—
            self.migration_log.append({
                "timestamp": datetime.now().isoformat(),
                "operation": "add_columns",
                "table": table_name,
                "added_columns": [col['name'] for col in columns],
                "backup": backup_path,
                "success": True
            })
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ åˆ—å¤±è´¥: {e}")
            return False
    
    def rename_column(self, table_name: str, old_name: str, new_name: str) -> bool:
        """é‡å‘½ååˆ—ï¼ˆé€šè¿‡è¡¨é‡å»ºï¼‰"""
        try:
            logger.info(f"ğŸ”§ é‡å‘½åè¡¨ {table_name} çš„åˆ—: {old_name} -> {new_name}")
            
            # åˆ›å»ºå¤‡ä»½
            backup_path = self.create_backup(f"rename_column_{table_name}")
            
            # è·å–è¡¨ç»“æ„
            schema = self.get_table_schema(table_name)
            
            # ä¿®æ”¹åˆ—å
            new_columns = []
            for col in schema["columns"]:
                if col["name"] == old_name:
                    col = col.copy()
                    col["name"] = new_name
                new_columns.append(col)
            
            # ç”Ÿæˆæ–°çš„CREATEè¯­å¥
            new_create_sql = self._generate_new_create_sql(
                table_name, new_columns, schema["create_sql"]
            )
            
            with self.get_connection() as conn:
                trans = conn.begin()
                
                try:
                    # åˆ›å»ºä¸´æ—¶è¡¨
                    temp_table_name = f"{table_name}_temp_{int(datetime.now().timestamp())}"
                    temp_create_sql = new_create_sql.replace(table_name, temp_table_name)
                    conn.execute(text(temp_create_sql))
                    
                    # å¤åˆ¶æ•°æ®ï¼ˆæ˜ å°„æ—§åˆ—ååˆ°æ–°åˆ—åï¼‰
                    old_columns = [col["name"] for col in schema["columns"]]
                    new_column_names = [col["name"] for col in new_columns]
                    
                    old_columns_str = ", ".join(old_columns)
                    new_columns_str = ", ".join(new_column_names)
                    
                    copy_sql = f"""
                        INSERT INTO {temp_table_name} ({new_columns_str})
                        SELECT {old_columns_str} FROM {table_name}
                    """
                    
                    conn.execute(text(copy_sql))
                    
                    # åˆ é™¤åŸè¡¨å¹¶é‡å‘½å
                    conn.execute(text(f"DROP TABLE {table_name}"))
                    conn.execute(text(f"ALTER TABLE {temp_table_name} RENAME TO {table_name}"))
                    
                    # é‡å»ºç´¢å¼•å’Œè§¦å‘å™¨ï¼ˆéœ€è¦æ›´æ–°åˆ—åï¼‰
                    for index in schema["indexes"]:
                        if index["sql"]:
                            # æ›¿æ¢ç´¢å¼•ä¸­çš„æ—§åˆ—å
                            updated_sql = index["sql"].replace(old_name, new_name)
                            conn.execute(text(updated_sql))
                    
                    for trigger in schema["triggers"]:
                        if trigger["sql"]:
                            # æ›¿æ¢è§¦å‘å™¨ä¸­çš„æ—§åˆ—å
                            updated_sql = trigger["sql"].replace(old_name, new_name)
                            conn.execute(text(updated_sql))
                    
                    trans.commit()
                    
                    logger.info(f"âœ… æˆåŠŸé‡å‘½ååˆ—: {old_name} -> {new_name}")
                    
                    # è®°å½•è¿ç§»æ—¥å¿—
                    self.migration_log.append({
                        "timestamp": datetime.now().isoformat(),
                        "operation": "rename_column",
                        "table": table_name,
                        "old_name": old_name,
                        "new_name": new_name,
                        "backup": backup_path,
                        "success": True
                    })
                    
                    return True
                    
                except Exception as e:
                    trans.rollback()
                    self.restore_from_backup(backup_path)
                    raise
                    
        except Exception as e:
            logger.error(f"âŒ é‡å‘½ååˆ—å¤±è´¥: {e}")
            return False
    
    def get_migration_history(self) -> List[Dict[str, Any]]:
        """è·å–è¿ç§»å†å²"""
        return self.migration_log.copy()
    
    def cleanup_old_backups(self, keep_count: int = 10):
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        try:
            backup_files = list(self.backup_dir.glob("tggod_backup_*.db"))
            backup_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            
            if len(backup_files) > keep_count:
                for backup_file in backup_files[keep_count:]:
                    backup_file.unlink()
                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: {backup_file}")
                    
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†å¤‡ä»½æ–‡ä»¶å¤±è´¥: {e}")


class SQLiteMigrationProgressReporter:
    """SQLiteè¿ç§»è¿›åº¦æŠ¥å‘Šå™¨"""
    
    def __init__(self, websocket_manager=None):
        self.websocket_manager = websocket_manager
        self.current_operation = ""
        self.progress = 0
    
    async def report_progress(self, operation: str, progress: int = 0, details: str = ""):
        """æŠ¥å‘Šè¿ç§»è¿›åº¦"""
        self.current_operation = operation
        self.progress = progress
        
        progress_data = {
            "type": "migration_progress",
            "operation": operation,
            "progress": progress,
            "details": details
        }
        
        logger.info(f"ğŸ“Š è¿ç§»è¿›åº¦: {operation} - {details}")
        
        if self.websocket_manager:
            await self.websocket_manager.broadcast(progress_data)
    
    async def report_error(self, error: str, details: str = ""):
        """æŠ¥å‘Šè¿ç§»é”™è¯¯"""
        error_data = {
            "type": "migration_error",
            "error": error,
            "details": details,
            "operation": self.current_operation
        }
        
        logger.error(f"âŒ è¿ç§»é”™è¯¯: {error} - {details}")
        
        if self.websocket_manager:
            await self.websocket_manager.broadcast(error_data)
    
    async def report_success(self, message: str):
        """æŠ¥å‘Šè¿ç§»æˆåŠŸ"""
        success_data = {
            "type": "migration_success",
            "message": message,
            "operation": self.current_operation
        }
        
        logger.info(f"âœ… è¿ç§»æˆåŠŸ: {message}")
        
        if self.websocket_manager:
            await self.websocket_manager.broadcast(success_data)