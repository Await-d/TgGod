#!/usr/bin/env python3
"""
ä»»åŠ¡æ‰§è¡Œé…ç½®è¯Šæ–­å·¥å…·
æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­é…ç½®ä¿¡æ¯çš„æ­£ç¡®ä½¿ç”¨
"""
import os
import sys
import sqlite3
import json
import logging
from datetime import datetime
from typing import Dict, List, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def diagnose_task_execution_config(task_id: int = None):
    """è¯Šæ–­ä»»åŠ¡æ‰§è¡Œé…ç½®ä½¿ç”¨æƒ…å†µ"""
    db_path = "/app/data/tggod.db"
    
    if not os.path.exists(db_path):
        logger.error(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # èŽ·å–ä»»åŠ¡åˆ—è¡¨
        if task_id:
            cursor.execute("SELECT * FROM download_tasks WHERE id = ?", (task_id,))
            tasks = cursor.fetchall()
        else:
            cursor.execute("SELECT * FROM download_tasks ORDER BY created_at DESC LIMIT 5")
            tasks = cursor.fetchall()
        
        if not tasks:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡")
            return False
        
        # èŽ·å–å­—æ®µå
        cursor.execute("PRAGMA table_info(download_tasks)")
        task_columns = [col[1] for col in cursor.fetchall()]
        
        logger.info("ðŸ” ä»»åŠ¡æ‰§è¡Œé…ç½®è¯Šæ–­æŠ¥å‘Š")
        logger.info("=" * 60)
        
        for task_row in tasks:
            task_dict = dict(zip(task_columns, task_row))
            task_id = task_dict['id']
            
            logger.info(f"\nðŸ“‹ ä»»åŠ¡ ID: {task_id} - {task_dict['name']}")
            logger.info(f"   çŠ¶æ€: {task_dict['status']}")
            logger.info(f"   ç¾¤ç»„ ID: {task_dict['group_id']}")
            logger.info(f"   ä¸‹è½½è·¯å¾„: {task_dict['download_path']}")
            
            # èŽ·å–ç¾¤ç»„ä¿¡æ¯
            cursor.execute("SELECT id, title, username FROM telegram_groups WHERE id = ?", (task_dict['group_id'],))
            group_info = cursor.fetchone()
            if group_info:
                logger.info(f"   ðŸ“ ç›®æ ‡ç¾¤ç»„: {group_info[1]} (@{group_info[2] or 'N/A'})")
            else:
                logger.error(f"   âŒ ç¾¤ç»„ä¸å­˜åœ¨: ID {task_dict['group_id']}")
            
            # èŽ·å–å…³è”è§„åˆ™
            cursor.execute("""
                SELECT tra.rule_id, tra.is_active, tra.priority, fr.name
                FROM task_rule_associations tra
                JOIN filter_rules fr ON tra.rule_id = fr.id
                WHERE tra.task_id = ?
                ORDER BY tra.priority DESC
            """, (task_id,))
            rule_associations = cursor.fetchall()
            
            if rule_associations:
                logger.info(f"   ðŸŽ¯ å…³è”è§„åˆ™ ({len(rule_associations)} ä¸ª):")
                for rule_id, is_active, priority, rule_name in rule_associations:
                    status = "âœ… æ´»è·ƒ" if is_active else "âŒ éžæ´»è·ƒ"
                    logger.info(f"      - è§„åˆ™ ID {rule_id}: {rule_name} (ä¼˜å…ˆçº§: {priority}, {status})")
                    
                    # èŽ·å–è§„åˆ™è¯¦ç»†é…ç½®
                    cursor.execute("SELECT * FROM filter_rules WHERE id = ?", (rule_id,))
                    rule_row = cursor.fetchone()
                    if rule_row:
                        cursor.execute("PRAGMA table_info(filter_rules)")
                        rule_columns = [col[1] for col in cursor.fetchall()]
                        rule_dict = dict(zip(rule_columns, rule_row))
                        
                        # æ£€æŸ¥å…³é”®é…ç½®
                        config_items = []
                        if rule_dict.get('keywords'):
                            keywords = json.loads(rule_dict['keywords']) if isinstance(rule_dict['keywords'], str) else rule_dict['keywords']
                            config_items.append(f"å…³é”®è¯: {keywords}")
                        if rule_dict.get('exclude_keywords'):
                            exclude_keywords = json.loads(rule_dict['exclude_keywords']) if isinstance(rule_dict['exclude_keywords'], str) else rule_dict['exclude_keywords']
                            config_items.append(f"æŽ’é™¤å…³é”®è¯: {exclude_keywords}")
                        if rule_dict.get('media_types'):
                            media_types = json.loads(rule_dict['media_types']) if isinstance(rule_dict['media_types'], str) else rule_dict['media_types']
                            config_items.append(f"åª’ä½“ç±»åž‹: {media_types}")
                        if rule_dict.get('min_file_size'):
                            config_items.append(f"æœ€å°æ–‡ä»¶å¤§å°: {rule_dict['min_file_size']} å­—èŠ‚")
                        if rule_dict.get('max_file_size'):
                            config_items.append(f"æœ€å¤§æ–‡ä»¶å¤§å°: {rule_dict['max_file_size']} å­—èŠ‚")
                        if rule_dict.get('min_views'):
                            config_items.append(f"æœ€å°æµè§ˆé‡: {rule_dict['min_views']}")
                        if rule_dict.get('max_views'):
                            config_items.append(f"æœ€å¤§æµè§ˆé‡: {rule_dict['max_views']}")
                        
                        for config in config_items:
                            logger.info(f"        {config}")
            else:
                logger.error(f"   âŒ æ²¡æœ‰å…³è”çš„è§„åˆ™")
            
            # æ£€æŸ¥ä»»åŠ¡é…ç½®
            logger.info(f"   âš™ï¸ ä»»åŠ¡é…ç½®:")
            config_items = [
                f"Jellyfinç»“æž„: {bool(task_dict.get('use_jellyfin_structure'))}",
                f"åŒ…å«å…ƒæ•°æ®: {bool(task_dict.get('include_metadata'))}",
                f"ä¸‹è½½ç¼©ç•¥å›¾: {bool(task_dict.get('download_thumbnails'))}",
                f"æŒ‰æ—¥æœŸç»„ç»‡: {bool(task_dict.get('organize_by_date'))}",
                f"æœ€å¤§æ–‡ä»¶åé•¿åº¦: {task_dict.get('max_filename_length', 150)}"
            ]
            
            for config in config_items:
                logger.info(f"      {config}")
            
            # æ£€æŸ¥ä»»åŠ¡æ‰§è¡ŒåŽ†å²
            if task_dict['status'] in ['completed', 'failed']:
                logger.info(f"   ðŸ“Š æ‰§è¡Œç»Ÿè®¡:")
                logger.info(f"      æ€»æ¶ˆæ¯æ•°: {task_dict.get('total_messages', 0)}")
                logger.info(f"      å·²ä¸‹è½½: {task_dict.get('downloaded_messages', 0)}")
                logger.info(f"      è¿›åº¦: {task_dict.get('progress', 0)}%")
                if task_dict.get('error_message'):
                    logger.error(f"      é”™è¯¯ä¿¡æ¯: {task_dict['error_message']}")
                if task_dict.get('completed_at'):
                    logger.info(f"      å®Œæˆæ—¶é—´: {task_dict['completed_at']}")
        
        # æ£€æŸ¥æ¶ˆæ¯ç­›é€‰æƒ…å†µ
        logger.info(f"\nðŸ”¬ æ¶ˆæ¯ç­›é€‰éªŒè¯")
        logger.info("=" * 60)
        
        for task_row in tasks:
            task_dict = dict(zip(task_columns, task_row))
            task_id = task_dict['id']
            
            # èŽ·å–ç¾¤ç»„æ¶ˆæ¯æ€»æ•°
            cursor.execute("SELECT COUNT(*) FROM telegram_messages WHERE group_id = ?", (task_dict['group_id'],))
            total_messages = cursor.fetchone()[0]
            
            # èŽ·å–æœ‰åª’ä½“çš„æ¶ˆæ¯æ•°
            cursor.execute("""
                SELECT COUNT(*) FROM telegram_messages 
                WHERE group_id = ? AND media_type IS NOT NULL AND media_type != 'text'
            """, (task_dict['group_id'],))
            media_messages = cursor.fetchone()[0]
            
            logger.info(f"\nðŸ“‹ ä»»åŠ¡ {task_id} æ¶ˆæ¯ç­›é€‰æƒ…å†µ:")
            logger.info(f"   ç¾¤ç»„æ€»æ¶ˆæ¯æ•°: {total_messages}")
            logger.info(f"   æœ‰åª’ä½“æ¶ˆæ¯æ•°: {media_messages}")
            
            # æ¨¡æ‹Ÿè§„åˆ™ç­›é€‰
            cursor.execute("""
                SELECT tra.rule_id, fr.name
                FROM task_rule_associations tra
                JOIN filter_rules fr ON tra.rule_id = fr.id
                WHERE tra.task_id = ? AND tra.is_active = 1
                ORDER BY tra.priority DESC
            """, (task_id,))
            active_rules = cursor.fetchall()
            
            if active_rules:
                logger.info(f"   æ´»è·ƒè§„åˆ™ç­›é€‰ç»“æžœ:")
                for rule_id, rule_name in active_rules:
                    # ç®€å•çš„è§„åˆ™ç­›é€‰æµ‹è¯•
                    query = """
                        SELECT COUNT(*) FROM telegram_messages 
                        WHERE group_id = ? AND media_type IS NOT NULL AND media_type != 'text'
                    """
                    params = [task_dict['group_id']]
                    
                    # èŽ·å–è§„åˆ™é…ç½®è¿›è¡Œç­›é€‰
                    cursor.execute("SELECT * FROM filter_rules WHERE id = ?", (rule_id,))
                    rule_row = cursor.fetchone()
                    if rule_row:
                        cursor.execute("PRAGMA table_info(filter_rules)")
                        rule_columns = [col[1] for col in cursor.fetchall()]
                        rule_dict = dict(zip(rule_columns, rule_row))
                        
                        # æ·»åŠ æ–‡ä»¶å¤§å°ç­›é€‰
                        if rule_dict.get('min_file_size'):
                            query += " AND media_size >= ?"
                            params.append(rule_dict['min_file_size'])
                        if rule_dict.get('max_file_size'):
                            query += " AND media_size <= ?"
                            params.append(rule_dict['max_file_size'])
                        
                        # æ·»åŠ æµè§ˆé‡ç­›é€‰
                        if rule_dict.get('min_views'):
                            query += " AND (view_count >= ? OR view_count IS NULL)"
                            params.append(rule_dict['min_views'])
                        if rule_dict.get('max_views'):
                            query += " AND view_count <= ?"
                            params.append(rule_dict['max_views'])
                    
                    cursor.execute(query, params)
                    filtered_count = cursor.fetchone()[0]
                    logger.info(f"      è§„åˆ™ '{rule_name}': {filtered_count} æ¡æ¶ˆæ¯ç¬¦åˆæ¡ä»¶")
        
        conn.close()
        logger.info(f"\nâœ… è¯Šæ–­å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"è¯Šæ–­å¤±è´¥: {e}")
        return False

def test_rule_filtering_logic():
    """æµ‹è¯•è§„åˆ™ç­›é€‰é€»è¾‘"""
    logger.info("\nðŸ§ª è§„åˆ™ç­›é€‰é€»è¾‘æµ‹è¯•")
    logger.info("=" * 60)
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„æµ‹è¯•é€»è¾‘
    # æ¯”å¦‚åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ŒéªŒè¯ç­›é€‰ç»“æžœç­‰
    
    logger.info("æµ‹è¯•åŠŸèƒ½å¼€å‘ä¸­...")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä»»åŠ¡æ‰§è¡Œé…ç½®è¯Šæ–­å·¥å…·")
    parser.add_argument("--task-id", type=int, help="æŒ‡å®šè¦è¯Šæ–­çš„ä»»åŠ¡ID")
    parser.add_argument("--test-filtering", action="store_true", help="æµ‹è¯•è§„åˆ™ç­›é€‰é€»è¾‘")
    
    args = parser.parse_args()
    
    logger.info("ðŸš€ å¯åŠ¨ä»»åŠ¡æ‰§è¡Œé…ç½®è¯Šæ–­å·¥å…·")
    
    success = True
    
    if args.test_filtering:
        test_rule_filtering_logic()
    else:
        success = diagnose_task_execution_config(args.task_id)
    
    if success:
        logger.info("âœ… è¯Šæ–­å·¥å…·æ‰§è¡ŒæˆåŠŸ")
        sys.exit(0)
    else:
        logger.error("âŒ è¯Šæ–­å·¥å…·æ‰§è¡Œå¤±è´¥")
        sys.exit(1)